# ACT 指令遵循与任务规划改造方案

面向目标：让 ACT 支持“自然语言指令 → 任务规划 → 轨迹下发”，并可在真实人体演示数据上训练。下列条目涵盖改造思路与理由。

## 1) 文本条件化的 CVAE 潜变量 z
- **在 encoder 注入文本**：用轻量文本编码器（CLIP text encoder 或小型 Transformer）得到指令向量 `t`; 在 `detr/models/detr_vae.py` 的 encoder 输入处，将 `t` 与 `qpos_embed`、`action_embed` 级联或通过 cross-attn 送入 `encoder`。理由：当前 `latent_proj` 只看动作+状态，加入指令可使 μ/σ 对任务语义敏感。
- **在 decoder 显式使用文本+z**：把采样的 `z` 先经 `latent_out_proj`，再与 `t` 拼接/相加后作为 decoder 额外 token 或 bias，同时为 `t` 另设 pos embedding。理由：避免 z 在推理时被指令忽略，确保动作生成依赖语言。
- **训练约束**：保留重构 L1 + KL；可额外加指令可分性（如 z → 任务分类头或 InfoNCE 对齐文本 embedding 与 z），避免 z 退化为无意义噪声。理由：多模态决策需要显式信号鼓励 z 携带语义。
- **推理路径**：推理时用文本编码器产生 `t`，采样/均值取样 z，走现有 chunk 解码路径。可保留先验采样以支持“无指令” fallback。理由：兼容原推理接口 (`policy.py:37-38`)。

## 2) ACT 动作 chunk 作为规划轨迹
- **直接输出规划点**：当前 ACT 解码得到关节空间 action 序列（长度=`chunk_size`），可视作高频 waypoints。理由：模型已内建前瞻规划，不需额外规划器。
- **下游接口**：增加后处理模块（独立于模型），负责限幅/平滑/插值、必要时做 IK 把关节/EE 轨迹转成控制指令，再交给力控/位置控控制器。理由：把安全约束与控制律与学习模型解耦。
- **多模态执行**：若希望从同一指令得到多种合法轨迹，可在推理时多次采样 z，做轨迹候选，选最符合安全/能耗/碰撞约束的轨迹。理由：利用 CVAE 的多样性而不牺牲执行安全。

## 3) 真实人体演示数据训练
- **数据格式对齐**：`utils.py` 的 `EpisodicDataset` 期望 HDF5，键包括 `/observations/images/{cam}`、`/observations/qpos`、`/action`。需要将真人演示映射到机械臂动作空间（关节或 EE）并对齐时间戳。理由：保持加载管线不改动即可复用训练脚本。
- **空间映射**：通过外参标定 + IK/几何标定将人体关键点/手势转为机械臂目标姿态或关节指令，写入 `/action`。理由：让模型看到与执行器一致的动作分布。
- **域差异与噪声处理**：对真实图像做颜色/光照/模糊增广，必要时用少量实机微调；对动作、时间戳做去抖动/对齐。理由：缓解 sim-to-real、传感噪声导致的分布漂移。
- **指令-动作对齐**：确保每段演示附带准确的自然语言指令，并在 HDF5 元数据中存储，以便 encoder 联合读取。理由：语言条件模型训练的监督源。

## 4) 开发与验证建议
- **实现顺序**：先加入文本编码+条件化 z（确保训练稳定），再打通轨迹后处理接口，最后替换/扩展数据集为真实演示。
- **快速验证**：保持原有 smoke（`uv run python -m compileall .`）+ 短暂训练 (`imitate_episodes.py --num_epochs 1 --batch_size 2`)；小规模真人人体子集上检查指令-动作对齐可视化。
- **度量**：记录 KL、L1/重构、指令解码准确率（若加分类/对齐头），以及多样性指标（不同 z 采样轨迹的平均差异）。理由：可观察 z 是否真正承载语义并影响规划。
